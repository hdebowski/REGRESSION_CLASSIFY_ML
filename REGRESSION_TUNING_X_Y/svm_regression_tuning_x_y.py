# -*- coding: utf-8 -*-
"""SVM_REGRESSION_TUNING_X_Y

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bCGaQZ8hir53r8U-GmpFcDXrhSFmIvdb
"""

import numpy as np
from sklearn.model_selection import train_test_split 
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV
from sklearn.svm import SVR 
from sklearn import preprocessing
from sklearn import preprocessing
from sklearn.metrics import make_scorer 
from sklearn.metrics import fbeta_score, make_scorer, mean_squared_error

from sklearn.metrics import make_scorer

X = np.sort(5 * np.random.rand(100, 2), axis=0)
y = np.matmul(X[:,0], X[:,1]) + 2*X[:,0] - 5*np.sin(X[:,1]) 
noise = np.random.rand(100,1).ravel()
y += noise

X = preprocessing.scale(X)
y = preprocessing.scale(y)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

scorer = make_scorer(mean_squared_error, greater_is_better = False)

tuned_parameters_Grid = {'C': [1, 10, 100, 1000],
                     'gamma': [1e-3, 1e-4],
                     'kernel': ['rbf']}

tuned_parameters_Random = {'C': np.logspace(0, 3, 1000),
                     'gamma': np.logspace(-3, -4, 100),
                     'kernel': ['rbf']}

Error_GA = []
Error_RA = []
Error_GAt = []
Error_RAt = []

epsilon = 0.0001

for i in range(100):
    clf_G = GridSearchCV(SVR(epsilon = epsilon), tuned_parameters_Grid, scoring = scorer, cv = 5)
    # trenowanie zainicjowanego modelu
    clf_G.fit(X_train, y_train)
    # Wyświetlenie najlepszego zestawu parametrów
    print(clf_G.best_params_)
    # predykcja działania modelu dla zestawu testowego
    y_true_G, y_pred_G = y_test, clf_G.predict(X_test)
    # zapełnianie listy wartością błędu MSE
    Error_GA.append(mean_squared_error(y_true_G, y_pred_G))
    # predykcja działania modelu dla zestawu treningowego
    y_true_Gt, y_pred_Gt = y_train, clf_G.predict(X_train)
    # zapełnianie listy wartością błędu MSE
    Error_GAt.append(mean_squared_error(y_true_Gt, y_pred_Gt))
        
    
    # Te same kroki tylko, że dla funkcji RandomizedSearchCV
    clf_R = RandomizedSearchCV(SVR(epsilon = epsilon), tuned_parameters_Random, scoring = scorer, cv = 5)
    clf_R.fit(X_train, y_train)
    print(clf_R.best_params_)
    
    y_true_R, y_pred_R = y_test, clf_R.predict(X_test)
    Error_RA.append(mean_squared_error(y_true_R, y_pred_R))
    y_true_Rt, y_pred_Rt = y_train, clf_R.predict(X_train)
    Error_RAt.append(mean_squared_error(y_true_Rt, y_pred_Rt))
    
    # Zwiększanie wartości parametru epsilon
    epsilon += .0001

#ZAD 5
#liniowa
X = np.sort(5 * np.random.rand(100, 2), axis=0)
y = np.matmul(X[:,0], X[:,1]) + 2*X[:,0] - 5*np.sin(X[:,1]) 
noise = np.random.rand(100,1).ravel()
y += noise
X = preprocessing.scale(X)
y = preprocessing.scale(y)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)
scorer = make_scorer(mean_squared_error, greater_is_better = False)
tuned_parameters_Grid = {'C': [1, 10, 100, 1000],
                     'gamma': [1e-3, 1e-4],
                     'kernel': ['linear']}
tuned_parameters_Random = {'C': np.logspace(0, 3, 1000),
                     'gamma': np.logspace(-3, -4, 100),
                     'kernel': ['linear']}
Error_GA = []
Error_RA = []
Error_GAt = []
Error_RAt = []
epsilon = 0.0001
for i in range(100):
    clf_G = GridSearchCV(SVR(epsilon = epsilon), tuned_parameters_Grid, scoring = scorer, cv = 5)
    # trenowanie zainicjowanego modelu
    clf_G.fit(X_train, y_train)
    # Wyświetlenie najlepszego zestawu parametrów
    print(clf_G.best_params_)
    # predykcja działania modelu dla zestawu testowego
    y_true_G, y_pred_G = y_test, clf_G.predict(X_test)
    # zapełnianie listy wartością błędu MSE
    Error_GA.append(mean_squared_error(y_true_G, y_pred_G))
    # predykcja działania modelu dla zestawu treningowego
    y_true_Gt, y_pred_Gt = y_train, clf_G.predict(X_train)
    # zapełnianie listy wartością błędu MSE
    Error_GAt.append(mean_squared_error(y_true_Gt, y_pred_Gt))
        
    
    # Te same kroki tylko, że dla funkcji RandomizedSearchCV
    clf_R = RandomizedSearchCV(SVR(epsilon = epsilon), tuned_parameters_Random, scoring = scorer, cv = 5)
    clf_R.fit(X_train, y_train)
    print(clf_R.best_params_)
    
    y_true_R, y_pred_R = y_test, clf_R.predict(X_test)
    Error_RA.append(mean_squared_error(y_true_R, y_pred_R))
    y_true_Rt, y_pred_Rt = y_train, clf_R.predict(X_train)
    Error_RAt.append(mean_squared_error(y_true_Rt, y_pred_Rt))
    
    # Zwiększanie wartości parametru epsilon
    epsilon += .0001

#wielomianowa
X = np.sort(5 * np.random.rand(100, 2), axis=0)
y = np.matmul(X[:,0], X[:,1]) + 2*X[:,0] - 5*np.sin(X[:,1]) 
noise = np.random.rand(100,1).ravel()
y += noise
X = preprocessing.scale(X)
y = preprocessing.scale(y)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)
scorer = make_scorer(mean_squared_error, greater_is_better = False)
tuned_parameters_Grid = {'C': [1, 10, 100, 1000],
                     'gamma': [1e-3, 1e-4],
                     'kernel': ['poly']}
tuned_parameters_Random = {'C': np.logspace(0, 3, 1000),
                     'gamma': np.logspace(-3, -4, 100),
                     'kernel': ['poly']}
Error_GA = []
Error_RA = []
Error_GAt = []
Error_RAt = []
epsilon = 0.0001
for i in range(100):
    clf_G = GridSearchCV(SVR(epsilon = epsilon), tuned_parameters_Grid, scoring = scorer, cv = 5)
    # trenowanie zainicjowanego modelu
    clf_G.fit(X_train, y_train)
    # Wyświetlenie najlepszego zestawu parametrów
    print(clf_G.best_params_)
    # predykcja działania modelu dla zestawu testowego
    y_true_G, y_pred_G = y_test, clf_G.predict(X_test)
    # zapełnianie listy wartością błędu MSE
    Error_GA.append(mean_squared_error(y_true_G, y_pred_G))
    # predykcja działania modelu dla zestawu treningowego
    y_true_Gt, y_pred_Gt = y_train, clf_G.predict(X_train)
    # zapełnianie listy wartością błędu MSE
    Error_GAt.append(mean_squared_error(y_true_Gt, y_pred_Gt))
        
    
    # Te same kroki tylko, że dla funkcji RandomizedSearchCV
    clf_R = RandomizedSearchCV(SVR(epsilon = epsilon), tuned_parameters_Random, scoring = scorer, cv = 5)
    clf_R.fit(X_train, y_train)
    print(clf_R.best_params_)
    
    y_true_R, y_pred_R = y_test, clf_R.predict(X_test)
    Error_RA.append(mean_squared_error(y_true_R, y_pred_R))
    y_true_Rt, y_pred_Rt = y_train, clf_R.predict(X_train)
    Error_RAt.append(mean_squared_error(y_true_Rt, y_pred_Rt))
    
    # Zwiększanie wartości parametru epsilon
    epsilon += .0001

